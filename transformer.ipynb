{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10290470,"sourceType":"datasetVersion","datasetId":6368656}],"dockerImageVersionId":30822,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import math\nimport torch\nimport torch.nn as nn\nfrom torch import Tensor\nimport torch.nn.functional as F\nimport numpy as np\nfrom typing import Optional, Tuple\nimport os\nimport copy\nimport time\n\nfrom torch.autograd import Variable\nfrom torch.nn.utils import clip_grad_norm_","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-12-25T01:39:06.234198Z","iopub.execute_input":"2024-12-25T01:39:06.234554Z","iopub.status.idle":"2024-12-25T01:39:10.142945Z","shell.execute_reply.started":"2024-12-25T01:39:06.234526Z","shell.execute_reply":"2024-12-25T01:39:10.141936Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"class Embeddings(nn.Module):\n  def __init__(self, vocab_num, d_model):\n    super(Embeddings,self).__init__()\n    self.emb = nn.Embedding(vocab_num,d_model)\n    self.d_model = d_model\n  def forward(self, x):\n\n    return self.emb(x) * math.sqrt(self.d_model)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-25T01:39:10.144254Z","iopub.execute_input":"2024-12-25T01:39:10.144692Z","iopub.status.idle":"2024-12-25T01:39:10.150284Z","shell.execute_reply.started":"2024-12-25T01:39:10.144663Z","shell.execute_reply":"2024-12-25T01:39:10.149111Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# class PositionalEncoding(nn.Module):\n\n#     def __init__(self, emb_dim, seq_len):\n#         super().__init__()\n\n#         self.encoding = torch.zeros(seq_len, emb_dim)\n#         self.encoding.requires_grad = False\n\n#         pos = torch.arange(0,seq_len).float().unsqueeze(dim=1)\n#         _2i = torch.arange(0,emb_dim,step=2).float()\n\n#         # self.encoding = (sequence_length, hidden_size)\n#         self.encoding[:, 0::2] = torch.sin(pos / (10000 ** (_2i/emb_dim)))\n#         self.encoding[:, 1::2] = torch.cos(pos / (10000 ** (_2i/emb_dim)))\n\n#     def forward(self, tensor):\n#         batch_size, sequence_length = tensor.size()\n\n#         # (sequence_length, hidden_size)\n#         return self.encoding[:sequence_length, :]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-25T01:39:10.152029Z","iopub.execute_input":"2024-12-25T01:39:10.152336Z","iopub.status.idle":"2024-12-25T01:39:10.169458Z","shell.execute_reply.started":"2024-12-25T01:39:10.152308Z","shell.execute_reply":"2024-12-25T01:39:10.168275Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"class PositionalEncoding(nn.Module):\n    def __init__(self, emb_dim, max_seq_len):\n        super().__init__()\n        self.encoding = torch.zeros(max_seq_len, emb_dim)\n        self.encoding.requires_grad = False\n\n        pos = torch.arange(0, max_seq_len).float().unsqueeze(dim=1)\n        _2i = torch.arange(0, emb_dim, step=2).float()\n\n        # Populate the positional encoding matrix\n        self.encoding[:, 0::2] = torch.sin(pos / (10000 ** (_2i / emb_dim)))\n        self.encoding[:, 1::2] = torch.cos(pos / (10000 ** (_2i / emb_dim)))\n\n    def forward(self, tensor):\n        # Adjust the positional encoding dynamically to match input length\n        seq_len = tensor.size(1)  # Sequence length of the input tensor\n        return self.encoding[:seq_len, :].unsqueeze(0).to(tensor.device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-25T01:39:10.170882Z","iopub.execute_input":"2024-12-25T01:39:10.171241Z","iopub.status.idle":"2024-12-25T01:39:10.187664Z","shell.execute_reply.started":"2024-12-25T01:39:10.171201Z","shell.execute_reply":"2024-12-25T01:39:10.186448Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"def self_attention(query, key, value, mask=None):\n  key_transpose = torch.transpose(key,-2,-1)\n  matmul_result = torch.matmul(query,key_transpose)\n  d_k = query.size()[-1]\n  attention_score = matmul_result/math.sqrt(d_k)\n\n  if mask is not None:\n    attention_score = attention_score.masked_fill(mask == 0, -1e20)\n\n  softmax_attention_score = F.softmax(attention_score,dim=-1)\n  result = torch.matmul(softmax_attention_score,value)\n\n  return result, softmax_attention_score\n\nclass MultiHeadAttention(nn.Module):\n    r\"\"\"\n    Multi-Head Attention proposed in \"Attention Is All You Need\"\n    Instead of performing a single attention function with d_model-dimensional keys, values, and queries,\n    project the queries, keys and values h times with different, learned linear projections to d_head dimensions.\n    These are concatenated and once again projected, resulting in the final values.\n    Multi-head attention allows the model to jointly attend to information from different representation\n    subspaces at different positions.\n\n    MultiHead(Q, K, V) = Concat(head_1, ..., head_h) · W_o\n        where head_i = Attention(Q · W_q, K · W_k, V · W_v)\n\n    Args:\n        dim (int): The dimension of model (default: 512)\n        num_attention_heads (int): The number of attention heads. (default: 8)\n\n    Inputs: query, key, value, mask\n        - **query** (batch, q_len, d_model): tensor containing projection vector for decoders.\n        - **key** (batch, k_len, d_model): tensor containing projection vector for encoders.\n        - **value** (batch, v_len, d_model): tensor containing features of the encoded input sequence.\n        - **mask** (-): tensor containing indices to be masked\n\n    Returns: output, attn\n        - **output** (batch, output_len, dimensions): tensor containing the attended output features.\n        - **attn** (batch * num_attention_heads, v_len): tensor containing the attention (alignment) from the encoders outputs.\n    \"\"\"\n    def __init__(self, head_num , d_model, dropout = 0.1):\n        super(MultiHeadAttention, self).__init__()\n\n        assert d_model % head_num == 0, \"hidden_dim % num_attention_heads should be zero.\"\n\n        self.head_num = head_num\n        self.d_model = dim\n        self.d_k = self.d_v = dim // head_num\n\n        self.w_q = nn.Linear(dim,dim) # or self.w_q = nn.Linear(d_model, head_num * d_head)\n        self.w_k = nn.Linear(dim,dim)\n        self.w_v = nn.Linear(dim,dim)\n        self.w_o = nn.Linear(dim,dim)\n\n        self.self_attention = self_attention\n        self.dropout = nn.Dropout(p=dropout)\n\n    def forward(self, query, key, value, mask = None):\n      if mask is not None:\n        # Same mask applied to all h heads.\n        mask = mask.unsqueeze(1)\n\n      batche_num = query.size(0)\n\n      query = self.w_q(query).view(batche_num, -1, self.head_num, self.d_k).transpose(1, 2)\n      key = self.w_k(key).view(batche_num, -1, self.head_num, self.d_k).transpose(1, 2)\n      value = self.w_v(value).view(batche_num, -1, self.head_num, self.d_k).transpose(1, 2)\n\n      attention_result, attention_score = self.self_attention(query, key, value, mask)\n\n\n      attention_result = attention_result.transpose(1,2).contiguous().view(batche_num, -1, self.head_num * self.d_k)\n\n\n      return self.w_o(attention_result)\n     ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-25T01:39:10.188513Z","iopub.execute_input":"2024-12-25T01:39:10.188813Z","iopub.status.idle":"2024-12-25T01:39:10.206184Z","shell.execute_reply.started":"2024-12-25T01:39:10.188787Z","shell.execute_reply":"2024-12-25T01:39:10.205187Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"class FeedForward(nn.Module):\n  def __init__(self,d_model, dropout = 0.1):\n    super(FeedForward,self).__init__()\n    self.w_1 = nn.Linear(d_model, d_model*4)\n    self.w_2 = nn.Linear(d_model*4, d_model)\n    self.dropout = nn.Dropout(p=dropout)\n\n  def forward(self, x):\n    return self.w_2(self.dropout(F.relu(self.w_1(x))))\n     ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-25T01:39:10.207234Z","iopub.execute_input":"2024-12-25T01:39:10.207635Z","iopub.status.idle":"2024-12-25T01:39:10.229423Z","shell.execute_reply.started":"2024-12-25T01:39:10.207601Z","shell.execute_reply":"2024-12-25T01:39:10.228372Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"class Encoder(nn.Module):\n  def __init__(self, d_model, head_num, dropout):\n    super(Encoder,self).__init__()\n    self.multi_head_attention = MultiHeadAttention(d_model= d_model, head_num = head_num)\n    self.layer_norm1 = nn.LayerNorm(d_model)\n\n    self.feed_forward = FeedForward(d_model)\n    self.layer_norm2 = nn.LayerNorm(d_model)\n\n  def forward(self, input, mask):\n    out = self.layer_norm1(input + self.multi_head_attention(input, input, input, mask))\n    out = self.layer_norm2(out + self.feed_forward(out))\n\n    return out\n\n\nclass Decoder(nn.Module):\n  def __init__(self, d_model,head_num, dropout):\n    super(Decoder,self).__init__()\n    self.masked_multi_head_attention = MultiHeadAttention(d_model= d_model, head_num= head_num)\n    self.layer_norm1 = nn.LayerNorm(d_model)\n\n    self.encoder_decoder_attention = MultiHeadAttention(d_model= d_model, head_num= head_num)\n    self.layer_norm2 = nn.LayerNorm(d_model)\n\n    self.feed_forward= FeedForward(d_model)\n    self.layer_norm3 = nn.LayerNorm(d_model)\n\n\n  def forward(self, target, encoder_output, target_mask, encoder_mask):\n    # target, x, target_mask, input_mask\n    x = self.layer_norm1(target, lambda x: self.masked_multi_head_attention(x, x, x, target_mask))\n    x = self.layer_norm2(x, lambda x: self.encoder_decoder_attention(x, encoder_output, encoder_output, encoder_mask))\n    x = self.layer_norm3(x, self.feed_forward)\n\n    return x\n     ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-25T01:39:10.230533Z","iopub.execute_input":"2024-12-25T01:39:10.231061Z","iopub.status.idle":"2024-12-25T01:39:10.249643Z","shell.execute_reply.started":"2024-12-25T01:39:10.231016Z","shell.execute_reply":"2024-12-25T01:39:10.248521Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"def clones(module, N):\n    return nn.ModuleList([copy.deepcopy(module) for _ in range(N)])\n\n\nclass TransformerLM(nn.Module):\n  def __init__(self, vocab_size, dim,  depth, max_seq_len, head_num, dropout= 0.1):\n    super(TransformerLM,self).__init__()\n\n    self.token_emb= nn.Embedding(vocab_size, dim)\n    self.position_emb = PositionalEncoding(dim,max_seq_len)\n    self.encoders = clones(Encoder(d_model=dim, head_num=head_num, dropout=dropout), depth)\n    self.norm = nn.LayerNorm(dim)\n    self.lm_head = nn.Sequential(\n            nn.Linear(dim, dim),\n            nn.Linear(dim, vocab_size)\n            )\n  def subsequent_mask(self, size):\n    \"Mask out subsequent positions.\"\n    attn_shape = (1, size, size)\n    subsequent_mask = np.triu(np.ones(attn_shape), k=1).astype('uint8')\n    return torch.from_numpy(subsequent_mask) == 0\n\n  def forward(self, input_ids, input_mask = None):\n    if input_mask is None:\n       input_mask = self.subsequent_mask(max_seq_len).to(device)\n\n    x = self.token_emb(input_ids)\n    x = x + self.position_emb(input_ids).type_as(x)\n\n    for encoder in self.encoders:\n      x = encoder(x, input_mask)\n    x = self.norm(x)\n\n    return self.lm_head(x)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-25T01:39:10.252879Z","iopub.execute_input":"2024-12-25T01:39:10.253267Z","iopub.status.idle":"2024-12-25T01:39:10.275482Z","shell.execute_reply.started":"2024-12-25T01:39:10.253214Z","shell.execute_reply":"2024-12-25T01:39:10.274335Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"text_file = '/kaggle/input/spa-data/spa.txt'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-25T01:39:10.277861Z","iopub.execute_input":"2024-12-25T01:39:10.278423Z","iopub.status.idle":"2024-12-25T01:39:10.297585Z","shell.execute_reply.started":"2024-12-25T01:39:10.278378Z","shell.execute_reply":"2024-12-25T01:39:10.296337Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"with open(text_file) as f:\n    lines = f.read().split(\"\\n\")[:1600]\n\ntext_pairs = []\nfor line in lines:\n    parts = line.split(\"\\t\")\n    if len(parts) >= 2:  # Ensure there are at least two elements\n        eng = parts[0]\n        spa = parts[1]\n        spa = \"[start] \" + spa + \" [end]\"\n        text_pairs.append((eng, spa))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-25T01:39:10.298650Z","iopub.execute_input":"2024-12-25T01:39:10.298994Z","iopub.status.idle":"2024-12-25T01:39:10.741612Z","shell.execute_reply.started":"2024-12-25T01:39:10.298961Z","shell.execute_reply":"2024-12-25T01:39:10.740445Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"import random\nfor _ in range(5):\n    print(random.choice(text_pairs))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-25T01:39:10.742608Z","iopub.execute_input":"2024-12-25T01:39:10.742869Z","iopub.status.idle":"2024-12-25T01:39:10.749410Z","shell.execute_reply.started":"2024-12-25T01:39:10.742847Z","shell.execute_reply":"2024-12-25T01:39:10.748388Z"}},"outputs":[{"name":"stdout","text":"('We saw it.', '[start] Lo vimos. [end]')\n('Tom knew.', '[start] Tom tenía constancia de ello. [end]')\n(\"It's me!\", '[start] Soy yo. [end]')\n(\"He's a DJ.\", '[start] Él es DJ. [end]')\n('He smiled.', '[start] Sonrió. [end]')\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"random.shuffle(text_pairs)\nnum_val_samples = int(0.15 * len(text_pairs))\nnum_train_samples = len(text_pairs) - 2 * num_val_samples\ntrain_pairs = text_pairs[:num_train_samples]\nval_pairs = text_pairs[num_train_samples : num_train_samples + num_val_samples]\ntest_pairs = text_pairs[num_train_samples + num_val_samples :]\n\nprint(f\"{len(text_pairs)} total pairs\")\nprint(f\"{len(train_pairs)} training pairs\")\nprint(f\"{len(val_pairs)} validation pairs\")\nprint(f\"{len(test_pairs)} test pairs\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-25T01:39:10.750570Z","iopub.execute_input":"2024-12-25T01:39:10.750851Z","iopub.status.idle":"2024-12-25T01:39:10.771107Z","shell.execute_reply.started":"2024-12-25T01:39:10.750819Z","shell.execute_reply":"2024-12-25T01:39:10.770000Z"}},"outputs":[{"name":"stdout","text":"1600 total pairs\n1120 training pairs\n240 validation pairs\n240 test pairs\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"import pathlib\nimport random\nimport string\nimport re\nimport numpy as np\nimport tensorflow as tf\n\nimport tensorflow.data as tf_data\nimport tensorflow.strings as tf_strings\n\nimport keras\nfrom keras import layers\nfrom keras.layers import TextVectorization","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-25T01:39:10.772317Z","iopub.execute_input":"2024-12-25T01:39:10.772642Z","iopub.status.idle":"2024-12-25T01:39:21.001601Z","shell.execute_reply.started":"2024-12-25T01:39:10.772615Z","shell.execute_reply":"2024-12-25T01:39:21.000578Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"strip_chars = string.punctuation + \"¿\" # the inverted question mark is for spanish\nstrip_chars = strip_chars.replace(\"[\", \"\")\nstrip_chars = strip_chars.replace(\"]\", \"\")\n# remove all special characters\n\nbatch_size = 32 # the number of samples to process at once during training.\n\nall_texts = [pair[0] for pair in text_pairs] + [pair[1] for pair in text_pairs]\nunique_tokens = set()\nfor text in all_texts:\n    unique_tokens.update(text.split())\nvocab_size = len(unique_tokens)\n\nprint(\"vocab_size: \" , vocab_size)\n\ndef custom_standardization(input_string):\n    lowercase = tf_strings.lower(input_string)  # Convert to lowercase\n    return tf_strings.regex_replace(lowercase, \"[%s]\" % re.escape(strip_chars), \"\")  # Remove punctuation\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-25T01:39:21.002798Z","iopub.execute_input":"2024-12-25T01:39:21.003651Z","iopub.status.idle":"2024-12-25T01:39:21.015367Z","shell.execute_reply.started":"2024-12-25T01:39:21.003605Z","shell.execute_reply":"2024-12-25T01:39:21.014361Z"}},"outputs":[{"name":"stdout","text":"vocab_size:  2292\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"def format_dataset(eng, spa): # takes eng and spa text pairs as input\n# English texts are fed to the encoder and Spanish texts are fed to the decoder\n    eng = eng_vectorization(eng)\n    spa = spa_vectorization(spa)\n    return (\n        {\n            \"encoder_inputs\": eng,\n            \"decoder_inputs\": spa[:, :-1], # exclude the last token ; used it as input to the decorder during training\n        },\n        spa[:, 1:], # Spanish texts excluding the first token; target output for the decorder\n    )\n\n\ndef make_dataset(pairs): # takes a list of text pairs and prepares tensorflow dataset\n    eng_texts, spa_texts = zip(*pairs) # split pairs\n    eng_texts = list(eng_texts)\n    spa_texts = list(spa_texts)\n    dataset = tf_data.Dataset.from_tensor_slices((eng_texts, spa_texts)) # creates a dataset\n    dataset = dataset.batch(batch_size)\n    dataset = dataset.map(format_dataset)\n    return dataset.cache().shuffle(2048).prefetch(16)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-25T01:39:21.016641Z","iopub.execute_input":"2024-12-25T01:39:21.016990Z","iopub.status.idle":"2024-12-25T01:39:21.034280Z","shell.execute_reply.started":"2024-12-25T01:39:21.016950Z","shell.execute_reply":"2024-12-25T01:39:21.033231Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"max_seq_len = 5","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-25T01:39:21.035307Z","iopub.execute_input":"2024-12-25T01:39:21.035739Z","iopub.status.idle":"2024-12-25T01:39:21.054888Z","shell.execute_reply.started":"2024-12-25T01:39:21.035704Z","shell.execute_reply":"2024-12-25T01:39:21.053536Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"eng_vectorization = TextVectorization(\n        max_tokens=vocab_size,\n        output_mode=\"int\",\n        output_sequence_length=max_seq_len,\n)\nspa_vectorization = TextVectorization(\n    max_tokens=vocab_size,\n    output_mode=\"int\",\n    output_sequence_length=max_seq_len + 1,\n    standardize=custom_standardization,\n)\ntrain_eng_texts = [pair[0] for pair in train_pairs]\ntrain_spa_texts = [pair[1] for pair in train_pairs]\neng_vectorization.adapt(train_eng_texts)\nspa_vectorization.adapt(train_spa_texts)\n\ntrain_ds = make_dataset(train_pairs)\ntest_ds = make_dataset(test_pairs)\nval_ds = make_dataset(val_pairs)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-25T01:39:21.056302Z","iopub.execute_input":"2024-12-25T01:39:21.056614Z","iopub.status.idle":"2024-12-25T01:39:21.785032Z","shell.execute_reply.started":"2024-12-25T01:39:21.056584Z","shell.execute_reply":"2024-12-25T01:39:21.783876Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nsentence_lengths = [len(sentence.split()) for sentence in all_texts]  # Replace with your data\nplt.hist(sentence_lengths, bins=20)\nplt.title(\"Sentence Length Distribution\")\nplt.xlabel(\"Length\")\nplt.ylabel(\"Frequency\")\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-25T01:39:21.786066Z","iopub.execute_input":"2024-12-25T01:39:21.786411Z","iopub.status.idle":"2024-12-25T01:39:22.127259Z","shell.execute_reply.started":"2024-12-25T01:39:21.786381Z","shell.execute_reply":"2024-12-25T01:39:22.126195Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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\n"},"metadata":{}}],"execution_count":18},{"cell_type":"code","source":"sentence_lengths = [len(sentence.split()) for sentence in all_texts]\ncoverage = [sum(l <= seq_len for l in sentence_lengths) / len(sentence_lengths) for seq_len in range(1, 11)]\nfor seq_len, cov in enumerate(coverage, 1):\n    print(f\"Max Seq Len: {seq_len}, Coverage: {cov*100:.2f}%\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-25T01:39:22.128359Z","iopub.execute_input":"2024-12-25T01:39:22.128707Z","iopub.status.idle":"2024-12-25T01:39:22.141137Z","shell.execute_reply.started":"2024-12-25T01:39:22.128667Z","shell.execute_reply":"2024-12-25T01:39:22.139910Z"}},"outputs":[{"name":"stdout","text":"Max Seq Len: 1, Coverage: 2.00%\nMax Seq Len: 2, Coverage: 37.97%\nMax Seq Len: 3, Coverage: 62.00%\nMax Seq Len: 4, Coverage: 84.56%\nMax Seq Len: 5, Coverage: 97.47%\nMax Seq Len: 6, Coverage: 99.50%\nMax Seq Len: 7, Coverage: 99.88%\nMax Seq Len: 8, Coverage: 99.97%\nMax Seq Len: 9, Coverage: 100.00%\nMax Seq Len: 10, Coverage: 100.00%\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"# Define model parameters\ndim = 128\ndepth = 2\nnum_epochs = 20  # Increased number of epochs for better training\nbatch_size = 16\nlearning_rate = 3e-4  # Adjusted learning rate ; 3e-4 not bad\nhead_num = 4","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-25T01:39:22.142444Z","iopub.execute_input":"2024-12-25T01:39:22.142824Z","iopub.status.idle":"2024-12-25T01:39:22.163848Z","shell.execute_reply.started":"2024-12-25T01:39:22.142782Z","shell.execute_reply":"2024-12-25T01:39:22.162651Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"from torch.optim.lr_scheduler import ReduceLROnPlateau","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-25T01:39:22.165046Z","iopub.execute_input":"2024-12-25T01:39:22.165482Z","iopub.status.idle":"2024-12-25T01:39:22.181280Z","shell.execute_reply.started":"2024-12-25T01:39:22.165440Z","shell.execute_reply":"2024-12-25T01:39:22.180177Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"# Lists to store results\nlosses = []\ntimes = []\nepoch_losses = []\ngradient_norms = []\n\n# Device configuration\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel = TransformerLM(vocab_size, dim, depth, max_seq_len, head_num, dropout=0.1).to(device)\n\n# Define loss function and optimizer\ncriterion = torch.nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\nscheduler = ReduceLROnPlateau(optimizer, 'min', patience=2, factor=0.5)  # Learning rate scheduler\n\n# Generate dummy data for the given sequence length\nids = torch.randint(0, vocab_size, (batch_size, max_seq_len * 100)).to(device)  # Adjust size as needed\nnum_batches = ids.size(1) // max_seq_len\n\nprint(f\"Sequence Length: {max_seq_len}, Num Batches: {num_batches}\")\n\n# Train the model\nstart_time = time.time()\ntotal_loss = 0\n\nfor epoch in range(num_epochs):\n    epoch_loss = 0\n    model.train()  # Ensure the model is in training mode\n    for i in range(0, ids.size(1) - max_seq_len, max_seq_len):\n        # Get mini-batches\n        inputs = ids[:, i:i + max_seq_len].to(device)\n        targets = ids[:, (i + 1):(i + 1) + max_seq_len].to(device)\n\n        # Forward pass\n        input_lengths = (torch.ones(batch_size) * max_seq_len).to(torch.int32)  # A tensor of the same length for each sequence\n        outputs = model(inputs)  # Process TransformerLM's forward method\n        output_flat = outputs.view(-1, vocab_size)  # Reshaped\n\n        # Backward pass\n        loss = criterion(output_flat, targets.reshape(-1))\n\n        optimizer.zero_grad()\n        loss.backward()\n\n        # Calculate gradient norm\n        total_norm = 0\n        for param in model.parameters():\n            if param.grad is not None:\n                param_norm = param.grad.data.norm(2)\n                total_norm += param_norm.item() ** 2\n        total_norm = total_norm ** 0.5\n        gradient_norms.append(total_norm)\n\n        clip_grad_norm_(model.parameters(), 0.5)\n        optimizer.step()\n\n        total_loss += loss.item()\n        epoch_loss += loss.item()\n\n    epoch_losses.append(epoch_loss / num_batches)\n    scheduler.step(epoch_loss / num_batches)  # Adjust learning rate based on validation loss\n\n    print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {epoch_loss / num_batches}\")\n\nelapsed_time = time.time() - start_time\navg_loss = total_loss / (num_batches * num_epochs)\nlosses.append(avg_loss)\ntimes.append(elapsed_time)\n\nprint(f\"Sequence Length: {max_seq_len}, Avg Loss: {avg_loss}, Time: {elapsed_time}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-25T01:39:22.182390Z","iopub.execute_input":"2024-12-25T01:39:22.182827Z","iopub.status.idle":"2024-12-25T01:40:00.141300Z","shell.execute_reply.started":"2024-12-25T01:39:22.182788Z","shell.execute_reply":"2024-12-25T01:40:00.139850Z"}},"outputs":[{"name":"stdout","text":"Sequence Length: 5, Num Batches: 100\nEpoch 1/20, Loss: 7.7024123573303225\nEpoch 2/20, Loss: 7.520085144042969\nEpoch 3/20, Loss: 7.311089887619018\nEpoch 4/20, Loss: 7.0785953187942505\nEpoch 5/20, Loss: 6.810819449424744\nEpoch 6/20, Loss: 6.5015155839920045\nEpoch 7/20, Loss: 6.1480703973770146\nEpoch 8/20, Loss: 5.757157740592956\nEpoch 9/20, Loss: 5.336379690170288\nEpoch 10/20, Loss: 4.892797060012818\nEpoch 11/20, Loss: 4.423728873729706\nEpoch 12/20, Loss: 3.9484826827049258\nEpoch 13/20, Loss: 3.471491460800171\nEpoch 14/20, Loss: 2.9975705575942992\nEpoch 15/20, Loss: 2.5454015278816224\nEpoch 16/20, Loss: 2.11982913851738\nEpoch 17/20, Loss: 1.7337144029140472\nEpoch 18/20, Loss: 1.3878335499763488\nEpoch 19/20, Loss: 1.1059815406799316\nEpoch 20/20, Loss: 0.8707897633314132\nSequence Length: 5, Avg Loss: 4.483187306374312, Time: 36.85336899757385\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"def tokenize(sentence, vectorization):\n    \"\"\"\n    Tokenizes a sentence into token IDs using the given vectorization model.\n\n    Args:\n        sentence (str): The input sentence.\n        vectorization: A vectorization object to tokenize the sentence.\n\n    Returns:\n        list: A list of token IDs for the given sentence.\n    \"\"\"\n    return vectorization(sentence).numpy()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-25T01:43:11.836577Z","iopub.execute_input":"2024-12-25T01:43:11.836937Z","iopub.status.idle":"2024-12-25T01:43:11.842054Z","shell.execute_reply.started":"2024-12-25T01:43:11.836909Z","shell.execute_reply":"2024-12-25T01:43:11.840523Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"# Reverse vocabulary for detokenization\nvocabulary = eng_vectorization.get_vocabulary()  # Returns a list of tokens\nreverse_vocab = {index: token for index, token in enumerate(vocabulary)}\n\n# Test sentences\nspanish_sentences = [\n    \"¿Tienes hermanos o hermanas?\",\n    \"Si nos levantamos lo suficientemente temprano, podremos ver el amanecer.\"\n]\n\n# Tokenize input sentences\ntokenized_inputs = [tokenize(sentence, spa_vectorization) for sentence in spanish_sentences]\ninput_tensors = torch.tensor(tokenized_inputs).to(device)\n\n# Add SOS token and pad the inputs to max_seq_len\nsos_token = eng_vectorization(\"<start>\").numpy()[0]\neos_token = eng_vectorization(\"<end>\").numpy()[0]\ninput_tensors = torch.cat(\n    [torch.full((len(input_tensors), 1), sos_token, device=device), input_tensors],\n    dim=1\n)\n\n# Translation loop\nmodel.eval()\ntranslated_sentences = []\nfor input_tensor in input_tensors:\n    input_tensor = input_tensor.unsqueeze(0)  # Add batch dimension\n    decoder_input = torch.tensor([[sos_token]], device=device)  # Start with SOS token\n\n    for _ in range(max_seq_len):\n        # Forward pass through the model\n        predictions = model(input_tensor)\n        predicted_token = torch.argmax(predictions, dim=-1)[:, -1].item()  # Get the last predicted token\n\n        if predicted_token == eos_token:\n            break\n        decoder_input = torch.cat([decoder_input, torch.tensor([[predicted_token]], device=device)], dim=1)\n\n    # Detokenize the output sequence\n    translated_sentence = detokenize(decoder_input[0].cpu().numpy(), reverse_vocab)\n    translated_sentences.append(translated_sentence)\n\n# Print results\nfor i, sentence in enumerate(spanish_sentences):\n    print(f\"Spanish: {sentence}\")\n    print(f\"English: {translated_sentences[i]}\")\n    print()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}